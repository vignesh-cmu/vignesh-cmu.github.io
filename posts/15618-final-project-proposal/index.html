<!DOCTYPE html>
<html lang="en-us">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta http-equiv="cache-control" content="max-age=0" />
    <meta http-equiv="cache-control" content="no-cache" />
    <meta http-equiv="expires" content="0" />
    <meta http-equiv="expires" content="Tue, 01 Jan 1980 1:00:00 GMT" />
    <meta http-equiv="pragma" content="no-cache" />

    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"}>
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">

    <meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff" />
    <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1b" />

    <meta name="description" content="15618 Final Project Proposal - Ziqi Liu and Vignesh S Rao">

    
        <title>15618 Final Project Proposal - Ziqi Liu and Vignesh S Rao | 15618 Final Project</title>
    

    
    <style>
        :root {
          --background: #ffffff;
        }
        @media (prefers-color-scheme: dark) {
          :root {
            --background: #1b1b1b;
          }
        }
        html {
            background-color: var(--background);
        }
        body {
            background-color: var(--background);
        }
    </style>

    
    <link rel="stylesheet" type="text/css" href="/style.min.dd7f4d768263b31dca99ccfd082ebb2574963449605bddaf5e9b91272f83dff2.css" media="all">
  </head>

  <body>
        
        <nav>
          <ul class="menu">
            
          </ul>
        </nav>
        




<div id="single-header">
  <h1>
    15618 Final Project Proposal - Ziqi Liu and Vignesh S Rao
  </h1>
  <div id="single-meta">
    
    
        <span class="datesub">Nov 17, 2024</span>
      

  </div>
</div>





<main><h1 id="extend-cilk-scheduler-with-suspend-resume-concurrency">Extend Cilk Scheduler with Suspend-Resume Concurrency</h1>
<h1 id="proposal-summary">Proposal Summary</h1>
<p>We are aiming to extend a research Cilk runtime library with concurrency support. Currently, Cilk only supports parallelism, as every worker have sole ownership on the task assigned through work-stealing during its lifetime, i.e. a running job will always be handled by 1 worker. We aim to extend Cilk semantics by giving tasks the ability to suspend, thereby unbinding from its current worker so the worker can execute other tasks; on the other hand, the suspended task should be able to resume execution once picked up by other workers. This is done by extending the current LazyD Cilk runtime codebase with two APIs: <code>__cilkrts_suspend</code>, <code>__cilkrts_resume</code>. Using these APIs, we&rsquo;ll be able to implement a consumer-producer queue execution in Cilk, which otherwise would be implemented using expensive locks.</p>
<h1 id="background">Background:</h1>
<p>We will be working on an existing Cilk implementation as part of the LazyD research by Prof. Seth Goldstein and PhD student Chrisma Pakha at Carnegie Mellon Univeristy. This version of Cilk runtime differs from traditional ones through its core principle of using lazy parallelism. Tasks will not be put into each worker&rsquo;s local work-stealing deque when a <code>cilk_spawn</code> is executed; instead, they will be retroactively exposed by the work owner upon a work request from the thief worker. The work exposure mechanisms uses stack unwinding techniques, which is too advanced for this project. However fortunately, the cilk scheduler in LazyD codebase still preserves the classic structure, which makes our job of extending it much easier.</p>
<p>Below are some pseudocode that illustrates our idea:</p>
<h2 id="extend-lazyd-cilk-runtime-library-with-suspend-and-resume">Extend LazyD Cilk runtime library with suspend and resume</h2>
<pre tabindex="0"><code class="language-[c]" data-lang="[c]">typedef struct {
  int count;
  int max_count;
  int* buf; // allocated with size max_count

  int hasWait; // 0 for no one waiting
  int waitId;
  _workcontext* suspCtx;

} __cilkrts_channel_t;

__cilkrts_channel_t *__cilkrts_channel_create(int max_count) {
  __cilkrts_channel_t* ch = malloc(sizeof(__cilkrts_channel_t)); 
  ch-&gt;count = 0;
  ch-&gt;max_count = max_count;

  return ch;
}

void __cilkrts_suspend(__cilkrts_channel_t *ch) {
  ch-&gt;waitId = threadId;
  ch-&gt;hasWait = true;

  getSP(ch-&gt;suspCtx[2]);
  __builtin_multiret_call(2, 1, (void*)&amp;dummyfcn, (void*)ch-&gt;suspCtx, &amp;&amp;
                wake_up, &amp;&amp;wake_up);
  
  // schedulerCtx[I_RIP] should be properly initialize to &amp;&amp;start_of_scheduler
  // schedulerCtx[I_RSP] should be @schedulerStack
  __builtin_uli_restore_context((void*)schedulerCtx);

wake_up: 
  // set up a return point after __cilkrts_resume 
  return;
}

void __cilkrts_might_resume(__cilkrts_channel_t *ch) {
  if (!ch-&gt;hasWait) 
    return;
  __cilkrts_resume(ch);
}

void __cilkrts_resume(__cilkrts_channel_t *ch) {
  int waitId = ch-&gt;waitId;
  void** suspCtx = ch-&gt;suspCtx;

  // push to waiter&#39;s ready queue
  __cilkrts_ready_ctx* rdy_ctx =  (__cilkrts_ready_ctx*)__cilkrts_create_ready_ctx();
  rdy_ctx-&gt;ctx = (_workcontext *) (suspCtx);
  rdy_ctx-&gt;bLazy = 1;
  __cilkrts_push_readyQ(rdy_ctx, waitId);
}
</code></pre><h2 id="implementing-a-channel-type-using-lazyd-scheduler">Implementing a Channel type using LazyD scheduler</h2>
<p>Using <code>__cilkrts_suspend</code> and <code>__cilkrts_might_resume</code>, the programmer could implement the following concurrency pattern using Cilk:</p>
<pre tabindex="0"><code class="language-[c]" data-lang="[c]">#define MAX_BUFF 4
#define N_ITERS 20

void* consumer(__cilkrst_channel_t *ch) {
  int item;
  for (int i = 0; i &lt; N_ITERS; i++) {
    item = (int) deq(ch);
    printf(&#34;consumed: %d\n&#34;, item);
  }
}

void* producer(__cilkrts_channel_t *ch) {
  for (int i = 0; i &lt; N_ITERS; i++) {
    printf(&#34;produced: %d\n&#34;, item);
    enq(ch, (void*)i);
  }
}

int main() {

  __cilkrts_channel_t *ch = __cilkrts_channel_create(MAX_BUFF);

  cilk_spawn producer(ch);

  consumer(ch);

  free(ch);
  return 0;
}
</code></pre><p>In order to implement <code>enq(ch, val)</code> and <code>deq(ch)</code>, we need to extend Cilk worker
with the ability to suspend and resume:</p>
<pre tabindex="0"><code class="language-[c]" data-lang="[c]">void enq(__cilkrts_channel_t *ch, void *val) {
  if (ch-&gt;count &lt; MAX_BUFF) {
    ch-&gt;buf[ch-&gt;count] = val;
    ch-&gt;count++;

    // wake up suspended deq caller
    __cilkrts_might_resume(ch);
    return;

  } else {
    // message queue is full
    __cilkrts_suspend(ch);

    assert(ch-&gt;count &lt; MAX_BUFF &amp;&amp; &#34;suspend did not wait long enough&#34;);
    ch-&gt;buf[ch-&gt;count] = val;
    ch-&gt;count++;
    return;
  }
}

void* deq(__cilkrts_channel_t *ch) {
  if (ch-&gt;count &gt; 0) {
    void* res = ch-&gt;buf[ch-&gt;count];
    ch-&gt;count--;

    // wake up suspended enq caller
    __cilkrts_might_resume(ch);
    return res;

  } else {
    // message queue runs out of items
    __cilkrts_suspend(ch);

    assert(ch-&gt;count &gt; 0 &amp;&amp; &#34;suspend did not wait long enough&#34;);
    void* res = ch-&gt;buf[ch-&gt;count];
    ch-&gt;count--;
    return res;
  }
}
</code></pre><h1 id="the-challenges">The Challenges:</h1>
<p>Our extension might increase parallelization overhead on the critical path, which defeats the main purpose of the LazyD, i.e. moving work exposure off the common path between parallel and sequential execution.</p>
<p>On the more practical side, debugging can be a real challenge because LazyD cilkruntime executes parallel tasks on stacklet (not system stack), which makes <code>gdb</code> backtracking useless. Moreover, work-stealing requires <code>setjmp</code> and <code>longjmp</code>, which makes tracking control-flow harder to reason.</p>
<h1 id="resources">Resources</h1>
<p>The code that we are writing is adding functionality to an existing codebase. The codebase we are starting from is the LazyD codebase which is not public yet. We will be extending this to support suspend and resume functionality for different tasks to ensure better parallelism. Since the code is meant to be used as a compiler extension, we don&rsquo;t need any specific computer hardware to test it on, just standard user computers are enough. The following papers discuss some of the concepts we are exploring and/or implementing.</p>
<ul>
<li>Cilk5: <a href="https://dl.acm.org/doi/pdf/10.1145/277650.277725"  target="_blank" rel="noreferrer nofollow">https://dl.acm.org/doi/pdf/10.1145/277650.277725</a>
</li>
<li>⁠Micheal &amp; Scott Concurrent Queue implementation: <a href="https://www.cs.rochester.edu/~scott/papers/1996_PODC_queues.pdf"  target="_blank" rel="noreferrer nofollow">https://www.cs.rochester.edu/~scott/papers/1996_PODC_queues.pdf</a>
</li>
<li>Concurrent Cilk: <a href="https://www.cs.ox.ac.uk/people/timothy.zakian/concCilkExtended.pdf"  target="_blank" rel="noreferrer nofollow">https://www.cs.ox.ac.uk/people/timothy.zakian/concCilkExtended.pdf</a>
</li>
</ul>
<h1 id="goals-and-deliverables">Goals and Deliverables:</h1>
<h2 id="working-extension-to-lazyd-cilk-runtime-with-suspend-and-resume-apis">Working extension to LazyD Cilk runtime with <code>suspend</code> and <code>resume</code> APIs</h2>
<p>By the end of this project, we should have a complete implementation of <code>__cilkrts_suspend</code>, <code>__cilkrts_resume</code> APIs, along with <code>__cilkrts_channel_t</code> along with <code>enq</code> and <code>deq</code> API.</p>
<h3 id="120-goals">120% Goals:</h3>
<p>During later parts of our project, we will experiment with different implementation of <code>__cilkrts_channel_t</code>. We will start with a simple lock-based implemenation, and later on move onto <code>cmpxchgq</code> based lock-free implementation.</p>
<h2 id="a-consumer-producer-application">A Consumer-Producer Application</h2>
<p>Using <code>enq</code> and <code>deq</code> API of the <code>__cilkrts_channel_t</code> type, we will evaluate correctness and performance of our <code>__cilkrts_suspend</code> and <code>__cilkrts_resume</code> implemenation. As our base goal, we will focus only on the following two special cases:</p>
<ul>
<li>single-producer, single-consumer</li>
<li>multiple-producer, multiple-consumer</li>
</ul>
<h3 id="120-goals-1">120% Goals:</h3>
<p>We will eventually move onto more complicated application beyond simple consumer-producer pattern. We are currently thinking of reimplementing the parallel Fibonacci benchmark using our channel.</p>
<h2 id="demo">Demo:</h2>
<p>At the poster session, we will present a performance chart of different implementation of our <code>__cilkrts_channel_t</code>. We will also present performance comparison with C-based implementation of the consumer-producer problem from 15-213 Intro to Computer System&rsquo;s lecture content.</p>
<h1 id="platform-choice">Platform Choice</h1>
<p>The group we are collaborating with is already using a server with Intel Xeon CPU E5-2680 v4 (2.4GHz) so we will be developing using the same machine. As mentioned before we don&rsquo;t have any specific requirements for the machine that we are developing this on. However all our testing and optimization is done for x86-64 machines running Linux. The reason for this is that the codebase we are starting with - LazyD - only supports x86-64 Linux machines currently.</p>
<h1 id="schedule">Schedule</h1>
<h3 id="week-nov-18th---nov-24th">Week Nov 18th - Nov 24th:</h3>
<p>Create file <code>uli-runtime/ss_channel.c</code> in runtime directory. Implement <code>__cilkrts_suspend</code> and <code>__cilkrts_resume</code> API as well <code>enq</code> and <code>deq</code>. Implement a single-producer-single-consumer test case and fully tested for correctness.</p>
<p>Read 15213 lecture notes for inspiration of concurrent multi-producer-multi-consumer queue implementation.</p>
<h3 id="week-nov-25th---dec-1st-thanksgiving">Week Nov 25th - Dec 1st (Thanksgiving):</h3>
<p>Implement <code>enq</code> and <code>deq</code> such that they support multiple producers and consumers concurrently:</p>
<ul>
<li>first use a lock-based implementation</li>
<li>then use a lock-free implementation</li>
</ul>
<p>Set up reference implementation from 15-213 lecture content.</p>
<h3 id="week-dec-2nd---dec-8th">Week Dec 2nd - Dec 8th:</h3>
<p>Implement <code>parfib</code> benchmark using our channel. Debug for correctness and performance.</p>
<h3 id="week-dec-8th---dec-15th">Week Dec 8th - Dec 15th:</h3>
<p>Write up final report and poster.</p>
</main>




<br>

<footer>

<script defer>
  document.addEventListener("keydown", function (e) {
    if (document.activeElement.isContentEditable) {
      return false;
    }
    if (document.activeElement.tagName == "INPUT") {
      return false;
    }
    if (e.altKey || e.ctrlKey || e.shiftKey) {
      return false;
    }
    var key = e.key;
    if (key === "h") {
      e.preventDefault();
      e.stopPropagation();
      window.location.href = "/";
    } else if (key === "t") {
      e.preventDefault();
      e.stopPropagation();
      window.location.href = `https://${location.hostname}/tags`;
    } else if (key === "i") {
      e.preventDefault();
      e.stopPropagation();
      const inputs = document.querySelectorAll("input");
      for (let i = 0; i < inputs.length; i++) {
        if (inputs[i].offsetParent !== null) {
          inputs[i].selectionStart = inputs[i].selectionEnd =
            inputs[i].value.length;
          inputs[i].focus();
          break;
        }
      }
    }
    return false;
  });
</script>


<script defer>
  function throttle(fn, wait) {
    var time = Date.now();
    return function () {
      var now = Date.now()
      if (time + wait - now < 0) {
        fn();
        time = now;
      }
    };
  }

  function scrollHandler() {
    const anchors = Array.from(document.querySelectorAll("body h2, body h3"));

    function scrollCallback() {
      var scrollTop = window.pageYOffset || document.documentElement.scrollTop;

      
      for (var i = 0; i < anchors.length; i++) {
        var anchorId = anchors[i].getAttribute("id");
        var link = document.querySelector(
          'nav ul li a[href="#' + anchorId + '"]',
        );
        if (link) {
          link.classList.remove("active-toc");
        }
      }

      
      for (var i = anchors.length - 1; i >= 0; i--) {
        var offsetTop = anchors[i].offsetTop;
        if (scrollTop > offsetTop - 75) {
          var anchorId = anchors[i].getAttribute("id");
          var link = document.querySelector(
            'nav ul li a[href="#' + anchorId + '"]',
          );
          if (link) {
            link.classList.add("active-toc");
            break;
          }
        }
      }
    }

    window.addEventListener(
      "scroll",
      throttle(scrollCallback, 300),
    );
  }
  setTimeout(scrollHandler, 100);
</script>

<script defer>
  function addCopyButtonToCodeBlocks() {
    
    const codeBlocks = document.querySelectorAll('code[class^="language-"]');

    codeBlocks.forEach((codeBlock) => {
      const copyButton = document.createElement("button");
      copyButton.classList.add("copy-code-button");
      copyButton.innerHTML = "copy";

      
      copyButton.addEventListener("click", () => {
        
        const elements = codeBlock.querySelectorAll(".cl");
        let codeToCopy = "";
        elements.forEach((element) => {
          codeToCopy += element.innerText;
        });
        navigator.clipboard.writeText(codeToCopy);

        
        copyButton.innerHTML = "copied!";
        setTimeout(() => {
          copyButton.innerHTML = "copy";
        }, 1500);
      });

      
      codeBlock.parentNode.before(copyButton);
    });
  }
  setTimeout(function () {
    addCopyButtonToCodeBlocks();
  }, 100);
</script>

<script>
window.store = {
    
    "http:\/\/localhost:1313\/": {
        "title": "15618 Final Project",
        "tags": [],
        "content": "", 
        "url": "http:\/\/localhost:1313\/"
    },
    
    "http:\/\/localhost:1313\/posts\/": {
        "title": "Posts",
        "tags": [],
        "content": "", 
        "url": "http:\/\/localhost:1313\/posts\/"
    },
    
    "http:\/\/localhost:1313\/posts\/15618-final-project-proposal\/": {
        "title": "15618 Final Project Proposal - Ziqi Liu and Vignesh S Rao",
        "tags": [],
        "content": "Extend Cilk Scheduler with Suspend-Resume Concurrency Proposal Summary We are aiming to extend a research Cilk runtime library with concurrency support. Currently, Cilk only supports parallelism, as every worker have sole ownership on the task assigned through work-stealing during its lifetime, i.e. a running job will always be handled by 1 worker. We aim to extend Cilk semantics by giving tasks the ability to suspend, thereby unbinding from its current worker so the worker can execute other tasks; on the other hand, the suspended task should be able to resume execution once picked up by other workers. This is done by extending the current LazyD Cilk runtime codebase with two APIs: __cilkrts_suspend, __cilkrts_resume. Using these APIs, we\u0026rsquo;ll be able to implement a consumer-producer queue execution in Cilk, which otherwise would be implemented using expensive locks.\nBackground: We will be working on an existing Cilk implementation as part of the LazyD research by Prof. Seth Goldstein and PhD student Chrisma Pakha at Carnegie Mellon Univeristy. This version of Cilk runtime differs from traditional ones through its core principle of using lazy parallelism. Tasks will not be put into each worker\u0026rsquo;s local work-stealing deque when a cilk_spawn is executed; instead, they will be retroactively exposed by the work owner upon a work request from the thief worker. The work exposure mechanisms uses stack unwinding techniques, which is too advanced for this project. However fortunately, the cilk scheduler in LazyD codebase still preserves the classic structure, which makes our job of extending it much easier.\nBelow are some pseudocode that illustrates our idea:\nExtend LazyD Cilk runtime library with suspend and resume typedef struct { int count; int max_count; int* buf; // allocated with size max_count int hasWait; // 0 for no one waiting int waitId; _workcontext* suspCtx; } __cilkrts_channel_t; __cilkrts_channel_t *__cilkrts_channel_create(int max_count) { __cilkrts_channel_t* ch = malloc(sizeof(__cilkrts_channel_t)); ch-\u0026gt;count = 0; ch-\u0026gt;max_count = max_count; return ch; } void __cilkrts_suspend(__cilkrts_channel_t *ch) { ch-\u0026gt;waitId = threadId; ch-\u0026gt;hasWait = true; getSP(ch-\u0026gt;suspCtx[2]); __builtin_multiret_call(2, 1, (void*)\u0026amp;dummyfcn, (void*)ch-\u0026gt;suspCtx, \u0026amp;\u0026amp; wake_up, \u0026amp;\u0026amp;wake_up); // schedulerCtx[I_RIP] should be properly initialize to \u0026amp;\u0026amp;start_of_scheduler // schedulerCtx[I_RSP] should be @schedulerStack __builtin_uli_restore_context((void*)schedulerCtx); wake_up: // set up a return point after __cilkrts_resume return; } void __cilkrts_might_resume(__cilkrts_channel_t *ch) { if (!ch-\u0026gt;hasWait) return; __cilkrts_resume(ch); } void __cilkrts_resume(__cilkrts_channel_t *ch) { int waitId = ch-\u0026gt;waitId; void** suspCtx = ch-\u0026gt;suspCtx; // push to waiter\u0026#39;s ready queue __cilkrts_ready_ctx* rdy_ctx = (__cilkrts_ready_ctx*)__cilkrts_create_ready_ctx(); rdy_ctx-\u0026gt;ctx = (_workcontext *) (suspCtx); rdy_ctx-\u0026gt;bLazy = 1; __cilkrts_push_readyQ(rdy_ctx, waitId); } Implementing a Channel type using LazyD scheduler Using __cilkrts_suspend and __cilkrts_might_resume, the programmer could implement the following concurrency pattern using Cilk:\n#define MAX_BUFF 4 #define N_ITERS 20 void* consumer(__cilkrst_channel_t *ch) { int item; for (int i = 0; i \u0026lt; N_ITERS; i++) { item = (int) deq(ch); printf(\u0026#34;consumed: %d\\n\u0026#34;, item); } } void* producer(__cilkrts_channel_t *ch) { for (int i = 0; i \u0026lt; N_ITERS; i++) { printf(\u0026#34;produced: %d\\n\u0026#34;, item); enq(ch, (void*)i); } } int main() { __cilkrts_channel_t *ch = __cilkrts_channel_create(MAX_BUFF); cilk_spawn producer(ch); consumer(ch); free(ch); return 0; } In order to implement enq(ch, val) and deq(ch), we need to extend Cilk worker with the ability to suspend and resume:\nvoid enq(__cilkrts_channel_t *ch, void *val) { if (ch-\u0026gt;count \u0026lt; MAX_BUFF) { ch-\u0026gt;buf[ch-\u0026gt;count] = val; ch-\u0026gt;count++; // wake up suspended deq caller __cilkrts_might_resume(ch); return; } else { // message queue is full __cilkrts_suspend(ch); assert(ch-\u0026gt;count \u0026lt; MAX_BUFF \u0026amp;\u0026amp; \u0026#34;suspend did not wait long enough\u0026#34;); ch-\u0026gt;buf[ch-\u0026gt;count] = val; ch-\u0026gt;count++; return; } } void* deq(__cilkrts_channel_t *ch) { if (ch-\u0026gt;count \u0026gt; 0) { void* res = ch-\u0026gt;buf[ch-\u0026gt;count]; ch-\u0026gt;count--; // wake up suspended enq caller __cilkrts_might_resume(ch); return res; } else { // message queue runs out of items __cilkrts_suspend(ch); assert(ch-\u0026gt;count \u0026gt; 0 \u0026amp;\u0026amp; \u0026#34;suspend did not wait long enough\u0026#34;); void* res = ch-\u0026gt;buf[ch-\u0026gt;count]; ch-\u0026gt;count--; return res; } } The Challenges: Our extension might increase parallelization overhead on the critical path, which defeats the main purpose of the LazyD, i.e. moving work exposure off the common path between parallel and sequential execution.\nOn the more practical side, debugging can be a real challenge because LazyD cilkruntime executes parallel tasks on stacklet (not system stack), which makes gdb backtracking useless. Moreover, work-stealing requires setjmp and longjmp, which makes tracking control-flow harder to reason.\nResources The code that we are writing is adding functionality to an existing codebase. The codebase we are starting from is the LazyD codebase which is not public yet. We will be extending this to support suspend and resume functionality for different tasks to ensure better parallelism. Since the code is meant to be used as a compiler extension, we don\u0026rsquo;t need any specific computer hardware to test it on, just standard user computers are enough. The following papers discuss some of the concepts we are exploring and/or implementing.\nCilk5: https://dl.acm.org/doi/pdf/10.1145/277650.277725 ⁠Micheal \u0026amp; Scott Concurrent Queue implementation: https://www.cs.rochester.edu/~scott/papers/1996_PODC_queues.pdf Concurrent Cilk: https://www.cs.ox.ac.uk/people/timothy.zakian/concCilkExtended.pdf Goals and Deliverables: Working extension to LazyD Cilk runtime with suspend and resume APIs By the end of this project, we should have a complete implementation of __cilkrts_suspend, __cilkrts_resume APIs, along with __cilkrts_channel_t along with enq and deq API.\n120% Goals: During later parts of our project, we will experiment with different implementation of __cilkrts_channel_t. We will start with a simple lock-based implemenation, and later on move onto cmpxchgq based lock-free implementation.\nA Consumer-Producer Application Using enq and deq API of the __cilkrts_channel_t type, we will evaluate correctness and performance of our __cilkrts_suspend and __cilkrts_resume implemenation. As our base goal, we will focus only on the following two special cases:\nsingle-producer, single-consumer multiple-producer, multiple-consumer 120% Goals: We will eventually move onto more complicated application beyond simple consumer-producer pattern. We are currently thinking of reimplementing the parallel Fibonacci benchmark using our channel.\nDemo: At the poster session, we will present a performance chart of different implementation of our __cilkrts_channel_t. We will also present performance comparison with C-based implementation of the consumer-producer problem from 15-213 Intro to Computer System\u0026rsquo;s lecture content.\nPlatform Choice The group we are collaborating with is already using a server with Intel Xeon CPU E5-2680 v4 (2.4GHz) so we will be developing using the same machine. As mentioned before we don\u0026rsquo;t have any specific requirements for the machine that we are developing this on. However all our testing and optimization is done for x86-64 machines running Linux. The reason for this is that the codebase we are starting with - LazyD - only supports x86-64 Linux machines currently.\nSchedule Week Nov 18th - Nov 24th: Create file uli-runtime/ss_channel.c in runtime directory. Implement __cilkrts_suspend and __cilkrts_resume API as well enq and deq. Implement a single-producer-single-consumer test case and fully tested for correctness.\nRead 15213 lecture notes for inspiration of concurrent multi-producer-multi-consumer queue implementation.\nWeek Nov 25th - Dec 1st (Thanksgiving): Implement enq and deq such that they support multiple producers and consumers concurrently:\nfirst use a lock-based implementation then use a lock-free implementation Set up reference implementation from 15-213 lecture content.\nWeek Dec 2nd - Dec 8th: Implement parfib benchmark using our channel. Debug for correctness and performance.\nWeek Dec 8th - Dec 15th: Write up final report and poster.\n", 
        "url": "http:\/\/localhost:1313\/posts\/15618-final-project-proposal\/"
    },
    
    "http:\/\/localhost:1313\/categories\/": {
        "title": "Categories",
        "tags": [],
        "content": "", 
        "url": "http:\/\/localhost:1313\/categories\/"
    },
    
    "http:\/\/localhost:1313\/tags\/": {
        "title": "Tags",
        "tags": [],
        "content": "", 
        "url": "http:\/\/localhost:1313\/tags\/"
    },
    
}
</script>
<script defer src="/js/lunr.js"></script>
<script defer src="/js/search.js"></script>

</footer>

</body>
</html>

